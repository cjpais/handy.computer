Okay, this is me just writing a bunch of random shit about Handy or speaking it rather.

I initially wrote handy when I had a broken finger and a cast on my right hand, which made it virtually impossible to do my day-to-day programming work without using my voice. I tried using a variety of speech-to-text applications like MacWhisper as well as SuperWhisper. However, with one hand, it really wasn't enough to solely have speech-to-text.

At the time, I didn't really know what specific features I would want to have, but I knew that I needed to be able to play with the code base to see what made the most sense for someone with limited typing ability, yet still wants to program, as well as do other tests on the computer.

I really needed the capability to extend the speech to text to other things like calling a large language model based on what I said, or highlighting some text and having the large language model rewrite something, or highlighting some code and having the large language model rewrite the whole piece of code.

While the application does not currently have these features embedded inside of it, the codebase should be ready enough for someone to add features of their own.

And overall, that's the main purpose of handy is to be a private cross platform speech to text application, which is very extensible for the power users who do want to extend it and make it their own. And I hope that people will contribute to the codebase and make it better, as well as it serve as an example of what a simple speech to text application can look like that doesn't necessarily require all the features in the world.

With this said, I'm also curious about, you know, some other things in the speech-to-text world that came up when writing the application as well as using it. And largely it comes down to the question of like, how do I wish to use my computer? And there's definitely some new ways of using the computer that come up here. And in particular, it would be really interesting to use the computer purely via my voice or pretty close to it. And having a base like this maybe allows for those things to happen with this being the MCP client and it being able to call out to a bunch of different MCP servers with voice being the first class citizen rather than a text box and something that works globally on the computer where you are rather than having to open some menu or something it's just ever present and you can just talk to it. So I'm curious about that direction. I hope someone takes this up. Whether it is built on top of handy or not, at least it is a good starting point for someone who wishes to do that. And I may get to this at some point.

Overall, handy as an application is quite simple, and you just press a keyboard shortcut to start recording, press it again to stop recording, or have it in push-to-talk mode where while you're talking, or while you're pushing the button rather, it's recording what you say, and then when you release it, it transcribes what you say, and paste it directly into whatever text field you're typing into, and it uses whisper, specifically whisper small, for doing this. That means all of this runs completely offline, and it should be GPU accelerated on virtually every machine that has a GPU, which is either a Mac or supports the Vulkan driver. I only have a limited number of machines to test this with, so I cannot say for certain that it does accelerate well on every machine. However, from what I have tested, it seems like it does accelerate quite well. And if it doesn't, this is something that hopefully we can fix.

There's like another large note in this that's really important, and that is, I really want this to be a community project, something that serves as a platform for this kind of extensibility, and is an example of a really simple code base that does this. yet remains powerful and extensible. And also this is my first time ever writing Rust and I really, really, really would like some help with the code base and getting it up to spec and there's a bunch of known issues and I wanna be transparent with those things that like here are the issues and here are some of the decisions that I made that maybe could be changed. And yeah, I just want it to be an open project that many people can contribute to as well as serve as a learning experience for me and Rust and hopefully get mentoring from someone who's more experienced.

And just as like a note on software in the world today, you know, part of this is like, I kind of just refused to pay for a piece of software, which fundamentally is free. And specifically a subscription. I don't want a subscription. I'm okay to pay for a well-crafted piece of software, but one that requires a subscription and potentially sends my data to the cloud for something that can be done fully on my own machine is, in my view, totally unacceptable. And that is, again, part of the reason here of like, I don't want to use something that tries to force a subscription down your throat. I don't trust that. And I kind of believe in access for accessibility software to everyone. And I think that's what this is. And I don't necessarily think that it should be a paid thing. This is ultimately a piece of accessibility software and was written as one initially. And that should be widely available to anyone, in my opinion.
